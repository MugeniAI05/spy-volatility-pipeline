{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9617c4-05f5-4131-a9b9-1929729ea793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/computation/expressions.py:22: UserWarning: Pandas requires version '2.10.2' or newer of 'numexpr' (version '2.8.7' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/masked.py:56: UserWarning: Pandas requires version '1.4.2' or newer of 'bottleneck' (version '1.3.7' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Runs automated checks on ingested price and options data:\n",
    "  - Price spike detection (z-score & IQR)\n",
    "  - Bid-ask inversion (bid > ask)\n",
    "  - Missing expiration gaps\n",
    "  - Implied volatility outliers\n",
    "  - Zero / negative price detection\n",
    "  - Data freshness check\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08221171-ed7c-4ee4-928a-ccac015cc3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s  %(levelname)-8s  %(message)s\",\n",
    "    handlers=[logging.FileHandler(\"pipeline.log\"), logging.StreamHandler()],\n",
    ")\n",
    "\n",
    "DB_PATH = \"quant.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae0f0bc-2379-4ac4-bfe7-c3fbaa2736e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds \n",
    "ZSCORE_SPIKE_THRESHOLD = 4.0    # daily return z-score beyond this is a spike\n",
    "IQR_MULTIPLIER = 3.0            # IQR fence for price level outliers\n",
    "MAX_BID_ASK_SPREAD_PCT = 0.50   # flag if (ask-bid)/mid > 50%\n",
    "MAX_IV_THRESHOLD = 5.0          # 500% IV is likely garbage data\n",
    "MIN_OPTION_ROWS_PER_EXPIRY = 5  # flag expirations with too few strikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cfe32cb-65e9-48cd-92cb-c0d320c15f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_price_data(engine) -> pd.DataFrame:\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        df = pd.read_sql(\"SELECT * FROM price_history ORDER BY date ASC\", conn)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    return df\n",
    "\n",
    "def load_options_data(engine) -> pd.DataFrame:\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        df = pd.read_sql(\"SELECT * FROM options_chain\", conn)\n",
    "    df[\"expiration\"] = pd.to_datetime(df[\"expiration\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f084e129-aab7-4455-925c-c32d249e3f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily return spikes \n",
    "def check_price_spikes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Flag rows where the daily return is a statistical outlier (z-score).\"\"\"\n",
    "    df = df.copy().sort_values(\"date\")\n",
    "    df[\"daily_return\"] = df[\"close\"].pct_change()\n",
    "\n",
    "    mean_ret = df[\"daily_return\"].mean()\n",
    "    std_ret = df[\"daily_return\"].std()\n",
    "    df[\"zscore\"] = (df[\"daily_return\"] - mean_ret) / std_ret\n",
    "\n",
    "    spikes = df[df[\"zscore\"].abs() > ZSCORE_SPIKE_THRESHOLD].copy()\n",
    "    spikes[\"anomaly_type\"] = \"price_spike\"\n",
    "    spikes[\"detail\"] = spikes.apply(\n",
    "        lambda r: f\"Return={r['daily_return']:.2%}, Z={r['zscore']:.2f}\", axis=1\n",
    "    )\n",
    "\n",
    "    log.info(f\"[CHECK 1] Price spikes (|z| > {ZSCORE_SPIKE_THRESHOLD}): {len(spikes)} found\")\n",
    "    for _, row in spikes.iterrows():\n",
    "        log.warning(f\"  Spike on {row['date'].date()}: {row['detail']}\")\n",
    "\n",
    "    return spikes[[\"date\", \"close\", \"daily_return\", \"zscore\", \"anomaly_type\", \"detail\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e2fd30-dacf-4607-a6c0-6da571f04535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero / negative prices\n",
    "def check_zero_negative_prices(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    bad = df[(df[\"close\"] <= 0) | (df[\"open\"] <= 0) | (df[\"high\"] <= 0) | (df[\"low\"] <= 0)].copy()\n",
    "    bad[\"anomaly_type\"] = \"zero_or_negative_price\"\n",
    "    bad[\"detail\"] = \"One or more OHLC fields <= 0\"\n",
    "\n",
    "    log.info(f\"[CHECK 2] Zero/negative prices: {len(bad)} found\")\n",
    "    if not bad.empty:\n",
    "        log.warning(bad[[\"date\", \"open\", \"high\", \"low\", \"close\"]].to_string())\n",
    "    return bad[[\"date\", \"close\", \"anomaly_type\", \"detail\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae4edc84-8d15-44bc-9365-a32c32c0dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHLC consistency \n",
    "def check_ohlc_consistency(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"High must be >= Low, and High >= Open/Close, Low <= Open/Close.\"\"\"\n",
    "    bad = df[\n",
    "        (df[\"high\"] < df[\"low\"]) |\n",
    "        (df[\"high\"] < df[\"open\"]) |\n",
    "        (df[\"high\"] < df[\"close\"]) |\n",
    "        (df[\"low\"] > df[\"open\"]) |\n",
    "        (df[\"low\"] > df[\"close\"])\n",
    "    ].copy()\n",
    "    bad[\"anomaly_type\"] = \"ohlc_inconsistency\"\n",
    "    bad[\"detail\"] = \"OHLC relationship violated\"\n",
    "\n",
    "    log.info(f\"[CHECK 3] OHLC inconsistencies: {len(bad)} found\")\n",
    "    for _, row in bad.iterrows():\n",
    "        log.warning(f\"  {row['date'].date()} O={row['open']} H={row['high']} L={row['low']} C={row['close']}\")\n",
    "    return bad[[\"date\", \"open\", \"high\", \"low\", \"close\", \"anomaly_type\", \"detail\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87bdcbe5-b7af-42b0-9cdd-c571693c2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing trading day gaps\n",
    "def check_missing_dates(df: pd.DataFrame, max_gap_days=5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Flags gaps larger than max_gap_days between consecutive trading dates.\n",
    "    (Normal weekends = 3-day gap; holidays can create 4-day gaps.)\n",
    "    \"\"\"\n",
    "    df = df.sort_values(\"date\").copy()\n",
    "    df[\"prev_date\"] = df[\"date\"].shift(1)\n",
    "    df[\"gap_days\"] = (df[\"date\"] - df[\"prev_date\"]).dt.days\n",
    "\n",
    "    gaps = df[df[\"gap_days\"] > max_gap_days].copy()\n",
    "    gaps[\"anomaly_type\"] = \"missing_date_gap\"\n",
    "    gaps[\"detail\"] = gaps[\"gap_days\"].apply(lambda g: f\"Gap of {g} calendar days\")\n",
    "\n",
    "    log.info(f\"[CHECK 4] Date gaps > {max_gap_days} days: {len(gaps)} found\")\n",
    "    for _, row in gaps.iterrows():\n",
    "        log.warning(f\"  Gap ending {row['date'].date()}: {row['detail']}\")\n",
    "\n",
    "    return gaps[[\"date\", \"gap_days\", \"anomaly_type\", \"detail\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648392da-8eae-4671-aba7-b89e445258ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bid-ask inversions \n",
    "def check_bid_ask_inversions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Bid > Ask is a data error; also flags extremely wide spreads.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Inversion: bid strictly greater than ask\n",
    "    inversions = df[df[\"bid\"] > df[\"ask\"]].copy()\n",
    "    inversions[\"anomaly_type\"] = \"bid_ask_inversion\"\n",
    "    inversions[\"detail\"] = inversions.apply(\n",
    "        lambda r: f\"bid={r['bid']:.2f} > ask={r['ask']:.2f}\", axis=1\n",
    "    )\n",
    "\n",
    "    # Wide spreads (non-inverted)\n",
    "    valid = df[(df[\"bid\"] > 0) & (df[\"ask\"] > 0) & (df[\"ask\"] >= df[\"bid\"])].copy()\n",
    "    valid[\"mid\"] = (valid[\"bid\"] + valid[\"ask\"]) / 2\n",
    "    valid[\"spread_pct\"] = (valid[\"ask\"] - valid[\"bid\"]) / valid[\"mid\"].replace(0, np.nan)\n",
    "    wide = valid[valid[\"spread_pct\"] > MAX_BID_ASK_SPREAD_PCT].copy()\n",
    "    wide[\"anomaly_type\"] = \"wide_bid_ask_spread\"\n",
    "    wide[\"detail\"] = wide[\"spread_pct\"].apply(lambda s: f\"Spread={s:.1%}\")\n",
    "\n",
    "    result = pd.concat([inversions, wide], ignore_index=True)\n",
    "    log.info(\n",
    "        f\"[CHECK 5] Bid-ask inversions: {len(inversions)} | Wide spreads: {len(wide)}\"\n",
    "    )\n",
    "    return result[[\"expiration\", \"option_type\", \"strike\", \"bid\", \"ask\", \"anomaly_type\", \"detail\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b96075f-9655-4421-af93-40e4ad9fa4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implied volatility outliers\n",
    "def check_iv_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Flag IV = 0 (missing) or IV > MAX_IV_THRESHOLD (garbage).\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    zero_iv = df[df[\"implied_vol\"] <= 0].copy()\n",
    "    zero_iv[\"anomaly_type\"] = \"zero_implied_vol\"\n",
    "    zero_iv[\"detail\"] = \"IV is zero or negative — likely missing data\"\n",
    "\n",
    "    high_iv = df[df[\"implied_vol\"] > MAX_IV_THRESHOLD].copy()\n",
    "    high_iv[\"anomaly_type\"] = \"extreme_implied_vol\"\n",
    "    high_iv[\"detail\"] = high_iv[\"implied_vol\"].apply(lambda v: f\"IV={v:.1%}\")\n",
    "\n",
    "    result = pd.concat([zero_iv, high_iv], ignore_index=True)\n",
    "    log.info(f\"[CHECK 6] IV outliers — zero: {len(zero_iv)}, extreme: {len(high_iv)}\")\n",
    "    return result[[\"expiration\", \"option_type\", \"strike\", \"implied_vol\", \"anomaly_type\", \"detail\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d7c72c5-98fe-4ef0-a294-f49521b3d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse expirations \n",
    "def check_sparse_expirations(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Flag expiration dates with very few strikes (suggests incomplete data).\"\"\"\n",
    "    counts = (\n",
    "        df.groupby([\"expiration\", \"option_type\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"strike_count\")\n",
    "    )\n",
    "    sparse = counts[counts[\"strike_count\"] < MIN_OPTION_ROWS_PER_EXPIRY].copy()\n",
    "    sparse[\"anomaly_type\"] = \"sparse_expiration\"\n",
    "    sparse[\"detail\"] = sparse[\"strike_count\"].apply(lambda c: f\"Only {c} strikes loaded\")\n",
    "\n",
    "    log.info(f\"[CHECK 7] Sparse expirations: {len(sparse)} found\")\n",
    "    for _, row in sparse.iterrows():\n",
    "        log.warning(\n",
    "            f\"  {row['expiration'].date()} {row['option_type']}: {row['detail']}\"\n",
    "        )\n",
    "    return sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac6c463b-1200-4099-af2a-491e75807dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data freshness \n",
    "def check_data_freshness(price_df: pd.DataFrame, max_stale_days=5):\n",
    "    \"\"\"Warn if the most recent price date is older than max_stale_days.\"\"\"\n",
    "    if price_df.empty:\n",
    "        log.warning(\"[CHECK 8] No price data to check freshness.\")\n",
    "        return\n",
    "\n",
    "    latest = price_df[\"date\"].max()\n",
    "    staleness = (pd.Timestamp.today() - latest).days\n",
    "    if staleness > max_stale_days:\n",
    "        log.warning(\n",
    "            f\"[CHECK 8] Data is STALE — latest date: {latest.date()}, \"\n",
    "            f\"{staleness} days ago (threshold: {max_stale_days})\"\n",
    "        )\n",
    "    else:\n",
    "        log.info(\n",
    "            f\"[CHECK 8] Data freshness OK — latest date: {latest.date()} ({staleness} days ago)\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40051c22-b3e9-4240-96e4-8c698a19b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary report\n",
    "def print_summary(anomaly_dict: dict):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"DATA QUALITY REPORT SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    total = 0\n",
    "    for check_name, df in anomaly_dict.items():\n",
    "        count = len(df)\n",
    "        total += count\n",
    "        status = \"  PASS\" if count == 0 else f\"   {count} ISSUE(S)\"\n",
    "        print(f\"  {check_name:<35} {status}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"  {'TOTAL ANOMALIES':<35} {total}\")\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b73de9e-e8e0-41c2-9104-b9db8f4015e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 22:59:32,885  INFO      VALIDATION PIPELINE START\n",
      "2026-02-17 22:59:32,901  INFO      [CHECK 1] Price spikes (|z| > 4.0): 4 found\n",
      "2026-02-17 22:59:32,902  WARNING     Spike on 2025-04-03: Return=-4.93%, Z=-4.83\n",
      "2026-02-17 22:59:32,902  WARNING     Spike on 2025-04-04: Return=-5.85%, Z=-5.73\n",
      "2026-02-17 22:59:32,903  WARNING     Spike on 2025-04-09: Return=10.50%, Z=10.09\n",
      "2026-02-17 22:59:32,903  WARNING     Spike on 2025-04-10: Return=-4.38%, Z=-4.30\n",
      "2026-02-17 22:59:32,906  INFO      [CHECK 2] Zero/negative prices: 0 found\n",
      "2026-02-17 22:59:32,908  INFO      [CHECK 3] OHLC inconsistencies: 0 found\n",
      "2026-02-17 22:59:32,911  INFO      [CHECK 4] Date gaps > 5 days: 0 found\n",
      "2026-02-17 22:59:32,913  INFO      [CHECK 8] Data freshness OK — latest date: 2026-02-17 (0 days ago)\n",
      "2026-02-17 22:59:32,917  INFO      [CHECK 5] Bid-ask inversions: 0 | Wide spreads: 47\n",
      "2026-02-17 22:59:32,921  INFO      [CHECK 6] IV outliers — zero: 0, extreme: 2\n",
      "2026-02-17 22:59:32,924  INFO      [CHECK 7] Sparse expirations: 0 found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA QUALITY REPORT SUMMARY\n",
      "============================================================\n",
      "  Price Spikes                           4 ISSUE(S)\n",
      "  Zero/Negative Prices                  PASS\n",
      "  OHLC Inconsistencies                  PASS\n",
      "  Missing Date Gaps                     PASS\n",
      "  Bid-Ask Issues                         47 ISSUE(S)\n",
      "  IV Outliers                            2 ISSUE(S)\n",
      "  Sparse Expirations                    PASS\n",
      "------------------------------------------------------------\n",
      "  TOTAL ANOMALIES                     53\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main entry\n",
    "def run_all_checks(engine=None):\n",
    "    if engine is None:\n",
    "        engine = create_engine(f\"sqlite:///{DB_PATH}\", echo=False)\n",
    "\n",
    "    log.info(\"VALIDATION PIPELINE START\")\n",
    "\n",
    "    price_df = load_price_data(engine)\n",
    "    options_df = load_options_data(engine)\n",
    "\n",
    "    # Price checks\n",
    "    spikes    = check_price_spikes(price_df)       if not price_df.empty else pd.DataFrame()\n",
    "    zeros     = check_zero_negative_prices(price_df) if not price_df.empty else pd.DataFrame()\n",
    "    ohlc      = check_ohlc_consistency(price_df)   if not price_df.empty else pd.DataFrame()\n",
    "    gaps      = check_missing_dates(price_df)       if not price_df.empty else pd.DataFrame()\n",
    "    check_data_freshness(price_df)\n",
    "\n",
    "    # Options checks\n",
    "    ba_issues = check_bid_ask_inversions(options_df) if not options_df.empty else pd.DataFrame()\n",
    "    iv_issues = check_iv_outliers(options_df)        if not options_df.empty else pd.DataFrame()\n",
    "    sparse    = check_sparse_expirations(options_df) if not options_df.empty else pd.DataFrame()\n",
    "\n",
    "    anomalies = {\n",
    "        \"Price Spikes\":           spikes,\n",
    "        \"Zero/Negative Prices\":   zeros,\n",
    "        \"OHLC Inconsistencies\":   ohlc,\n",
    "        \"Missing Date Gaps\":      gaps,\n",
    "        \"Bid-Ask Issues\":         ba_issues,\n",
    "        \"IV Outliers\":            iv_issues,\n",
    "        \"Sparse Expirations\":     sparse,\n",
    "    }\n",
    "\n",
    "    total = print_summary(anomalies)\n",
    "    return anomalies, total\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_all_checks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
