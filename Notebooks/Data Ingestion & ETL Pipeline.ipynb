{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0e86be0-1925-4816-ba93-2bfb1ffbcb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in /opt/anaconda3/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: sqlalchemy in /opt/anaconda3/lib/python3.12/site-packages (2.0.30)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (2.32.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (3.19.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: curl_cffi<0.14,>=0.7 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (6.33.5)\n",
      "Requirement already satisfied: websockets>=13.0 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from curl_cffi<0.14,>=0.7->yfinance) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from curl_cffi<0.14,>=0.7->yfinance) (2025.7.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12.0->curl_cffi<0.14,>=0.7->yfinance) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance pandas sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c390d401-2702-443f-ae78-994f36c1baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sqlite3\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1da189-0a65-4d03-b4c2-9cf66ce1d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging setup\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s  %(levelname)-8s  %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"pipeline.log\"),\n",
    "        logging.StreamHandler(),\n",
    "    ],\n",
    ")\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ea9f16e-82f8-4835-ad8d-91720d6f2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "DB_PATH = \"quant.db\"\n",
    "TICKER = \"SPY\"\n",
    "PRICE_PERIOD = \"2y\"          # 2 years of daily price history\n",
    "PRICE_INTERVAL = \"1d\"\n",
    "MAX_EXPIRATIONS = 5          # how many option expiry dates to pull\n",
    "RETRY_ATTEMPTS = 3\n",
    "RETRY_DELAY = 5              # seconds between retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f987567d-ef7d-439c-976c-0b1a3c6d9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database helpers \n",
    "def get_engine():\n",
    "    engine = create_engine(f\"sqlite:///{DB_PATH}\", echo=False)\n",
    "    return engine\n",
    "\n",
    "\n",
    "def create_tables(engine):\n",
    "    \"\"\"Create all tables if they don't exist.\"\"\"\n",
    "    ddl = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS price_history (\n",
    "        id          INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        ticker      TEXT    NOT NULL,\n",
    "        date        TEXT    NOT NULL,\n",
    "        open        REAL,\n",
    "        high        REAL,\n",
    "        low         REAL,\n",
    "        close       REAL,\n",
    "        adj_close   REAL,\n",
    "        volume      INTEGER,\n",
    "        ingested_at TEXT    DEFAULT (datetime('now')),\n",
    "        UNIQUE(ticker, date)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS options_chain (\n",
    "        id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        ticker          TEXT NOT NULL,\n",
    "        expiration      TEXT NOT NULL,\n",
    "        option_type     TEXT NOT NULL,   -- 'call' or 'put'\n",
    "        strike          REAL NOT NULL,\n",
    "        last_price      REAL,\n",
    "        bid             REAL,\n",
    "        ask             REAL,\n",
    "        volume          INTEGER,\n",
    "        open_interest   INTEGER,\n",
    "        implied_vol     REAL,\n",
    "        in_the_money    INTEGER,         -- boolean 0/1\n",
    "        ingested_at     TEXT DEFAULT (datetime('now')),\n",
    "        UNIQUE(ticker, expiration, option_type, strike)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS etl_log (\n",
    "        id          INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        run_time    TEXT DEFAULT (datetime('now')),\n",
    "        ticker      TEXT,\n",
    "        step        TEXT,\n",
    "        status      TEXT,\n",
    "        rows_loaded INTEGER,\n",
    "        message     TEXT\n",
    "    );\n",
    "    \"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        for stmt in ddl.strip().split(\";\"):\n",
    "            stmt = stmt.strip()\n",
    "            if stmt:\n",
    "                conn.execute(text(stmt))\n",
    "        conn.commit()\n",
    "    log.info(\"Tables verified / created.\")\n",
    "\n",
    "\n",
    "def log_etl_event(engine, ticker, step, status, rows=0, message=\"\"):\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(\n",
    "            text(\n",
    "                \"INSERT INTO etl_log (ticker, step, status, rows_loaded, message) \"\n",
    "                \"VALUES (:ticker, :step, :status, :rows, :message)\"\n",
    "            ),\n",
    "            {\"ticker\": ticker, \"step\": step, \"status\": status, \"rows\": rows, \"message\": message},\n",
    "        )\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ea3790-3147-420f-bb9f-2bb47b44db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry wrapper\n",
    "def retry_fetch(fn, *args, label=\"fetch\", **kwargs):\n",
    "    \"\"\"Call fn(*args, **kwargs) up to RETRY_ATTEMPTS times on failure.\"\"\"\n",
    "    for attempt in range(1, RETRY_ATTEMPTS + 1):\n",
    "        try:\n",
    "            result = fn(*args, **kwargs)\n",
    "            return result\n",
    "        except Exception as exc:\n",
    "            log.warning(f\"[{label}] Attempt {attempt}/{RETRY_ATTEMPTS} failed: {exc}\")\n",
    "            if attempt < RETRY_ATTEMPTS:\n",
    "                time.sleep(RETRY_DELAY)\n",
    "    raise RuntimeError(f\"[{label}] All {RETRY_ATTEMPTS} attempts failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b740bd91-68fc-46c9-a530-d3068f0f184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price history\n",
    "def ingest_price_history(engine, ticker=TICKER):\n",
    "    log.info(f\"Ingesting price history for {ticker} ({PRICE_PERIOD})...\")\n",
    "\n",
    "    def _fetch():\n",
    "        t = yf.Ticker(ticker)\n",
    "        df = t.history(period=PRICE_PERIOD, interval=PRICE_INTERVAL, auto_adjust=False)\n",
    "        return df\n",
    "\n",
    "    try:\n",
    "        df = retry_fetch(_fetch, label=\"price_history\")\n",
    "    except RuntimeError as e:\n",
    "        log_etl_event(engine, ticker, \"price_history\", \"FAILED\", message=str(e))\n",
    "        log.error(str(e))\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if df.empty:\n",
    "        msg = f\"No price data returned for {ticker}.\"\n",
    "        log.warning(msg)\n",
    "        log_etl_event(engine, ticker, \"price_history\", \"WARN\", message=msg)\n",
    "        return df\n",
    "\n",
    "    # Normalise columns\n",
    "    df = df.reset_index()\n",
    "    df.columns = [c.lower().replace(\" \", \"_\") for c in df.columns]\n",
    "    df[\"ticker\"] = ticker\n",
    "\n",
    "    # Convert date to string (SQLite-friendly)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Handle missing data\n",
    "    missing_before = df.isnull().sum().sum()\n",
    "    df[[\"open\", \"high\", \"low\", \"close\", \"adj_close\"]] = (\n",
    "        df[[\"open\", \"high\", \"low\", \"close\", \"adj_close\"]]\n",
    "        .ffill()          # forward-fill gaps (e.g. holidays)\n",
    "        .bfill()          # back-fill any leading NaN\n",
    "    )\n",
    "    df[\"volume\"] = df[\"volume\"].fillna(0).astype(int)\n",
    "    missing_after = df.isnull().sum().sum()\n",
    "    if missing_before:\n",
    "        log.info(f\"  Filled {missing_before - missing_after} missing price values.\")\n",
    "\n",
    "    # Keep only the columns we need\n",
    "    cols = [\"ticker\", \"date\", \"open\", \"high\", \"low\", \"close\", \"adj_close\", \"volume\"]\n",
    "    df = df[[c for c in cols if c in df.columns]]\n",
    "\n",
    "    # Upsert (INSERT OR REPLACE in SQLite)\n",
    "    rows_loaded = 0\n",
    "    with engine.connect() as conn:\n",
    "        for _, row in df.iterrows():\n",
    "            conn.execute(\n",
    "                text(\n",
    "                    \"INSERT OR REPLACE INTO price_history \"\n",
    "                    \"(ticker, date, open, high, low, close, adj_close, volume) \"\n",
    "                    \"VALUES (:ticker, :date, :open, :high, :low, :close, :adj_close, :volume)\"\n",
    "                ),\n",
    "                row.to_dict(),\n",
    "            )\n",
    "            rows_loaded += 1\n",
    "        conn.commit()\n",
    "\n",
    "    log.info(f\"  Loaded {rows_loaded} price rows for {ticker}.\")\n",
    "    log_etl_event(engine, ticker, \"price_history\", \"OK\", rows=rows_loaded)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a67d33f-033c-4d00-ae23-fa0a813dbcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options chain \n",
    "def ingest_options_chain(engine, ticker=TICKER):\n",
    "    log.info(f\"Ingesting options chain for {ticker}...\")\n",
    "\n",
    "    def _get_ticker():\n",
    "        return yf.Ticker(ticker)\n",
    "\n",
    "    try:\n",
    "        t = retry_fetch(_get_ticker, label=\"options_ticker\")\n",
    "        expirations = t.options\n",
    "    except Exception as e:\n",
    "        log_etl_event(engine, ticker, \"options_chain\", \"FAILED\", message=str(e))\n",
    "        log.error(f\"Could not fetch expirations: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if not expirations:\n",
    "        msg = \"No option expirations found.\"\n",
    "        log.warning(msg)\n",
    "        log_etl_event(engine, ticker, \"options_chain\", \"WARN\", message=msg)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Limit to nearest N expirations\n",
    "    expirations = expirations[:MAX_EXPIRATIONS]\n",
    "    log.info(f\"  Pulling {len(expirations)} expiration dates: {list(expirations)}\")\n",
    "\n",
    "    all_frames = []\n",
    "    for exp in expirations:\n",
    "        try:\n",
    "            chain = retry_fetch(t.option_chain, exp, label=f\"chain_{exp}\")\n",
    "            for opt_type, frame in [(\"call\", chain.calls), (\"put\", chain.puts)]:\n",
    "                frame = frame.copy()\n",
    "                frame[\"ticker\"] = ticker\n",
    "                frame[\"expiration\"] = exp\n",
    "                frame[\"option_type\"] = opt_type\n",
    "                all_frames.append(frame)\n",
    "        except Exception as e:\n",
    "            log.warning(f\"  Skipping expiration {exp}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not all_frames:\n",
    "        log.error(\"No options data collected.\")\n",
    "        log_etl_event(engine, ticker, \"options_chain\", \"FAILED\", message=\"No data\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.concat(all_frames, ignore_index=True)\n",
    "\n",
    "    # Normalise column names (yfinance uses camelCase)\n",
    "    rename_map = {\n",
    "        \"contractSymbol\": \"contract_symbol\",\n",
    "        \"lastPrice\": \"last_price\",\n",
    "        \"openInterest\": \"open_interest\",\n",
    "        \"impliedVolatility\": \"implied_vol\",\n",
    "        \"inTheMoney\": \"in_the_money\",\n",
    "    }\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    # Handle missing values\n",
    "    df[\"bid\"] = df.get(\"bid\", pd.Series(dtype=float)).fillna(0.0)\n",
    "    df[\"ask\"] = df.get(\"ask\", pd.Series(dtype=float)).fillna(0.0)\n",
    "    df[\"volume\"] = df.get(\"volume\", pd.Series(dtype=float)).fillna(0).astype(int)\n",
    "    df[\"open_interest\"] = df.get(\"open_interest\", pd.Series(dtype=float)).fillna(0).astype(int)\n",
    "    df[\"implied_vol\"] = df.get(\"implied_vol\", pd.Series(dtype=float)).fillna(0.0)\n",
    "    df[\"in_the_money\"] = df.get(\"in_the_money\", pd.Series(dtype=bool)).fillna(False).astype(int)\n",
    "\n",
    "    rows_loaded = 0\n",
    "    with engine.connect() as conn:\n",
    "        for _, row in df.iterrows():\n",
    "            try:\n",
    "                conn.execute(\n",
    "                    text(\n",
    "                        \"INSERT OR REPLACE INTO options_chain \"\n",
    "                        \"(ticker, expiration, option_type, strike, last_price, \"\n",
    "                        \"bid, ask, volume, open_interest, implied_vol, in_the_money) \"\n",
    "                        \"VALUES (:ticker, :expiration, :option_type, :strike, :last_price, \"\n",
    "                        \":bid, :ask, :volume, :open_interest, :implied_vol, :in_the_money)\"\n",
    "                    ),\n",
    "                    {\n",
    "                        \"ticker\": row[\"ticker\"],\n",
    "                        \"expiration\": row[\"expiration\"],\n",
    "                        \"option_type\": row[\"option_type\"],\n",
    "                        \"strike\": row.get(\"strike\", None),\n",
    "                        \"last_price\": row.get(\"last_price\", None),\n",
    "                        \"bid\": row.get(\"bid\", None),\n",
    "                        \"ask\": row.get(\"ask\", None),\n",
    "                        \"volume\": row.get(\"volume\", None),\n",
    "                        \"open_interest\": row.get(\"open_interest\", None),\n",
    "                        \"implied_vol\": row.get(\"implied_vol\", None),\n",
    "                        \"in_the_money\": row.get(\"in_the_money\", None),\n",
    "                    },\n",
    "                )\n",
    "                rows_loaded += 1\n",
    "            except Exception as e:\n",
    "                log.debug(f\"  Row insert error (skipping): {e}\")\n",
    "        conn.commit()\n",
    "\n",
    "    log.info(f\"  Loaded {rows_loaded} option rows for {ticker}.\")\n",
    "    log_etl_event(engine, ticker, \"options_chain\", \"OK\", rows=rows_loaded)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "453a6379-b9da-40ea-88a3-c739f3f8b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 22:30:25,860  INFO      ============================================================\n",
      "2026-02-17 22:30:25,864  INFO      ETL PIPELINE START\n",
      "2026-02-17 22:30:25,865  INFO      ============================================================\n",
      "2026-02-17 22:30:25,887  INFO      Tables verified / created.\n",
      "2026-02-17 22:30:25,888  INFO      Ingesting price history for SPY (2y)...\n",
      "2026-02-17 22:30:27,098  INFO        Loaded 500 price rows for SPY.\n",
      "2026-02-17 22:30:27,101  INFO      Ingesting options chain for SPY...\n",
      "2026-02-17 22:30:27,272  INFO        Pulling 5 expiration dates: ['2026-02-18', '2026-02-19', '2026-02-20', '2026-02-23', '2026-02-24']\n",
      "2026-02-17 22:30:28,353  INFO        Loaded 1046 option rows for SPY.\n",
      "2026-02-17 22:30:28,354  INFO      ============================================================\n",
      "2026-02-17 22:30:28,354  INFO      ETL COMPLETE — Price rows: 500, Option rows: 1046\n",
      "2026-02-17 22:30:28,354  INFO      ============================================================\n"
     ]
    }
   ],
   "source": [
    "# Entry point \n",
    "def run_etl():\n",
    "    log.info(\"=\" * 60)\n",
    "    log.info(\"ETL PIPELINE START\")\n",
    "    log.info(\"=\" * 60)\n",
    "\n",
    "    engine = get_engine()\n",
    "    create_tables(engine)\n",
    "\n",
    "    price_df = ingest_price_history(engine, TICKER)\n",
    "    options_df = ingest_options_chain(engine, TICKER)\n",
    "\n",
    "    log.info(\"=\" * 60)\n",
    "    log.info(f\"ETL COMPLETE — Price rows: {len(price_df)}, Option rows: {len(options_df)}\")\n",
    "    log.info(\"=\" * 60)\n",
    "    return price_df, options_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_etl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
